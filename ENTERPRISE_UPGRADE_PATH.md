# Enterprise Upgrade Path - Full-Featured Multi-Format Alert System

**Project:** alerts-sheets  
**Current State:** BNN + SMS support  
**Vision:** Enterprise-grade multi-format notification aggregation platform  
**Date:** December 18, 2025

---

## ğŸ¯ Executive Summary

This document outlines the architectural evolution from a working BNN/SMS notification forwarder to a **scalable enterprise platform** capable of handling multiple data formats, sources, and destinations with advanced features like analytics, ML-based enrichment, and real-time dashboards.

---

## ğŸ“Š Current Architecture Assessment

### Strengths âœ…
- **Robust BNN parsing** - Complex pipe-delimited format handled perfectly
- **Offline queue** - SQLite-based persistence with retry logic
- **Foreground service** - 24/7 operation with system survival
- **Deduplication** - 2-second window prevents duplicates
- **Multi-endpoint** - Parallel broadcasting to multiple URLs
- **Test framework** - Built-in payload testing

### Limitations âš ï¸
- **Single backend** - Only Google Sheets (no Firestore, SQL)
- **No enrichment** - Raw data only (no geocoding, property data)
- **Limited SMS** - Basic support, no advanced routing
- **No analytics** - Can't query historical data efficiently
- **Manual scaling** - No auto-scaling or load balancing
- **No AI/ML** - No predictive analytics or anomaly detection

---

## ğŸ—ï¸ Enterprise Architecture (Proposed)

### Phase 1: Backend Modernization (Weeks 1-4)

#### 1.1 Multi-Format Backend Handler

**Current:**
```javascript
// Code.gs
if (data.source === "sms") { handleSmsMessage() }
else { handleBnnIncident() }
```

**Enterprise:**
```javascript
// Cloud Function (Node.js/TypeScript)
class MessageRouter {
  route(message) {
    const handler = HandlerFactory.create(message.source);
    const enrichedData = await handler.process(message);
    await this.persist(enrichedData);
    await this.notify(enrichedData);
  }
}

// Handlers:
- BnnHandler.js (existing BNN logic)
- SmsHandler.js (existing SMS logic)
- EmailHandler.js (NEW - email alerts)
- WebhookHandler.js (NEW - generic webhook events)
- PagerDutyHandler.js (NEW - incident management)
- TwitterHandler.js (NEW - social media alerts)
- WeatherApiHandler.js (NEW - NWS alerts)
- GenericJsonHandler.js (NEW - catch-all for unknown formats)
```

**Benefits:**
- **Extensible:** Add new formats without touching existing code
- **Testable:** Each handler independently unit tested
- **Maintainable:** Single Responsibility Principle
- **Scalable:** Handlers can run in parallel

**Implementation Files:**
```
backend/
â”œâ”€â”€ handlers/
â”‚   â”œâ”€â”€ BaseHandler.ts (abstract class)
â”‚   â”œâ”€â”€ BnnHandler.ts
â”‚   â”œâ”€â”€ SmsHandler.ts
â”‚   â”œâ”€â”€ EmailHandler.ts
â”‚   â””â”€â”€ HandlerFactory.ts
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ EnrichmentService.ts (Phase 2)
â”‚   â”œâ”€â”€ GeocodingService.ts
â”‚   â””â”€â”€ NotificationService.ts
â””â”€â”€ index.ts (Cloud Function entry point)
```

---

#### 1.2 Dual Persistence Layer

**Current:** Google Sheets only

**Enterprise:** Multi-database strategy

```typescript
interface DataStore {
  write(record: Alert): Promise<void>;
  query(filters: QueryFilters): Promise<Alert[]>;
}

// Implementations:
class FirestoreStore implements DataStore { }  // Real-time queries
class BigQueryStore implements DataStore { }   // Analytics
class GoogleSheetsStore implements DataStore { } // User-friendly view
class PostgresStore implements DataStore { }   // Relational queries
```

**Data Flow:**
```
Alert arrives â†’ Process â†’ Write to:
  1. Firestore (primary, real-time)
  2. BigQuery (analytics, batch)
  3. Google Sheets (visualization)
  4. Postgres (optional, complex queries)
```

**Why Multiple Stores:**
- **Firestore:** Fast writes, real-time subscriptions, mobile app support
- **BigQuery:** Analyze millions of historical alerts, ML integration
- **Sheets:** User-friendly, stakeholder access, no training needed
- **Postgres:** Complex joins, legacy system integration

**Migration Strategy:**
```sql
-- Firestore Schema
collection: incidents
  â”œâ”€ document: incident_id
      â”œâ”€ source: "bnn" | "sms" | ...
      â”œâ”€ timestamp: Timestamp
      â”œâ”€ status: string
      â”œâ”€ location: GeoPoint (NEW - for map queries)
      â”œâ”€ raw: map (original data)
      â””â”€ enriched: map (Phase 2 data)

-- BigQuery Table
CREATE TABLE alerts.incidents (
  id STRING,
  source STRING,
  timestamp TIMESTAMP,
  location GEOGRAPHY, -- for spatial queries
  parsed_data JSON,
  enriched_data JSON,
  embedding ARRAY<FLOAT64> -- for ML similarity search
)
PARTITION BY DATE(timestamp);
```

---

#### 1.3 Enhanced Android App Architecture

**Current Structure:**
```
NotificationService â†’ Parser â†’ Queue â†’ Network â†’ Apps Script
```

**Enterprise Structure:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Android App (Edge Device)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Capture Layer (unchanged)              â”‚
â”‚  â”œâ”€ NotificationService                 â”‚
â”‚  â”œâ”€ SmsReceiver                         â”‚
â”‚  â””â”€ NEW: EmailReceiver, WebhookReceiverâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Processing Layer (enhanced)            â”‚
â”‚  â”œâ”€ BnnParser                           â”‚
â”‚  â”œâ”€ SmsParser                           â”‚
â”‚  â””â”€ NEW: PluginSystem for custom parsersâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Intelligence Layer (NEW)               â”‚
â”‚  â”œâ”€ LocalCache (reduce API calls)       â”‚
â”‚  â”œâ”€ PriorityQueue (critical first)      â”‚
â”‚  â”œâ”€ CompressionEngine (save bandwidth)  â”‚
â”‚  â””â”€ EdgeML (on-device classification)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Network Layer (enhanced)               â”‚
â”‚  â”œâ”€ RetryQueue (existing)               â”‚
â”‚  â”œâ”€ NEW: Batch uploads                  â”‚
â”‚  â”œâ”€ NEW: WebSocket streaming            â”‚
â”‚  â””â”€ NEW: P2P mesh for offline devices   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**New Android Components:**

1. **PluginSystem.kt** - Dynamic parser loading
```kotlin
interface AlertPlugin {
    fun canHandle(notification: Notification): Boolean
    fun parse(notification: Notification): ParsedData
}

class PluginManager {
    fun registerPlugin(plugin: AlertPlugin)
    fun findHandler(notification: Notification): AlertPlugin?
}

// Usage:
pluginManager.registerPlugin(BnnPlugin())
pluginManager.registerPlugin(SmsPlugin())
pluginManager.registerPlugin(PagerDutyPlugin()) // NEW
```

2. **PriorityQueue.kt** - Critical alerts first
```kotlin
class PriorityQueue {
    enum class Priority { CRITICAL, HIGH, NORMAL, LOW }
    
    fun enqueue(alert: Alert, priority: Priority) {
        // Critical alerts bypass queue, sent immediately
        // High alerts sent before NORMAL even if older
    }
}

// ML-based priority detection
class PriorityClassifier {
    fun classify(alert: ParsedData): Priority {
        // "Structure Fire" â†’ CRITICAL
        // "Smoke Condition" â†’ HIGH
        // "Standby" â†’ NORMAL
    }
}
```

3. **LocalCache.kt** - Reduce backend calls
```kotlin
class LocalCache {
    // Cache geocoding results
    fun getGeocode(address: String): LatLng?
    
    // Cache FD code translations
    fun getFdDescription(code: String): String?
    
    // Cache property data
    fun getPropertyInfo(address: String): PropertyData?
}
```

---

### Phase 2: Enrichment Pipeline (Weeks 5-8)

#### 2.1 Geocoding & Property Data

**Backend Service:**
```typescript
class EnrichmentPipeline {
  async enrich(alert: RawAlert): Promise<EnrichedAlert> {
    // 1. Geocode address
    const geocode = await this.geocodingService.resolve(alert.address);
    
    // 2. Fetch property data
    const property = await this.propertyService.lookup(alert.address);
    
    // 3. Translate FD codes
    const fdDescriptions = await this.fdCodeService.translate(alert.fdCodes);
    
    // 4. Historical context
    const history = await this.historicalService.getSimilar(alert);
    
    return {
      ...alert,
      geocode,
      property,
      fdDescriptions,
      history
    };
  }
}
```

**Services Required:**

1. **Geocoding Service** (Reuse existing Firestore cache!)
```typescript
class GeocodingService {
  async resolve(address: string): Promise<Geocode> {
    // 1. Check Firestore cache (your existing geocodes!)
    const cached = await this.cacheCheck(address);
    if (cached) return cached;
    
    // 2. Call Google Maps API
    const result = await this.mapsApi.geocode(address);
    
    // 3. Cache for reuse
    await this.cacheStore(address, result);
    return result;
  }
}
```

2. **Property Data Service**
```typescript
class PropertyDataService {
  async lookup(address: string): Promise<PropertyData> {
    // Call Attom, Estated, or BatchData APIs
    const data = await this.attomApi.query(address);
    return {
      yearBuilt: data.yearBuilt,
      squareFeet: data.squareFeet,
      stories: data.stories,
      construction: data.construction,
      occupancy: data.occupancy,
      ownerName: data.ownerName,
      assessedValue: data.assessedValue
    };
  }
}
```

3. **FD Code Translation Service**
```typescript
class FdCodeService {
  // Firestore collection: fd_codes
  // { code: "njn005", description: "North Bergen FD", coverage: GeoPolygon }
  
  async translate(codes: string[]): Promise<FdDescription[]> {
    const results = await Promise.all(
      codes.map(code => this.lookup(code))
    );
    return results;
  }
}
```

**Enriched Data Structure:**
```json
{
  "id": "#1845007",
  "source": "bnn",
  "raw": {
    "status": "New Incident",
    "state": "NJ",
    "address": "1107 Langford St",
    "incidentType": "Working Fire"
  },
  "enriched": {
    "geocode": {
      "lat": 40.7128,
      "lng": -74.0060,
      "accuracy": "ROOFTOP",
      "placeId": "ChIJ..."
    },
    "property": {
      "yearBuilt": 1925,
      "squareFeet": 2400,
      "stories": 2,
      "construction": "Wood Frame",
      "occupancy": "Single Family",
      "assessedValue": 450000
    },
    "fdCodes": [
      { "code": "njc691", "description": "Asbury Park FD Engine 691" },
      { "code": "nj233", "description": "Asbury Park FD Ladder 233" }
    ],
    "historicalContext": {
      "previousIncidents": 2,
      "lastIncident": "2023-05-15",
      "avgResponseTime": "4.2 minutes"
    }
  }
}
```

---

#### 2.2 AI/ML Enrichment

**Use Cases:**
1. **Incident Classification** - Auto-categorize beyond BNN types
2. **Severity Prediction** - Predict if incident will escalate
3. **Resource Optimization** - Suggest optimal unit dispatch
4. **Anomaly Detection** - Flag unusual patterns
5. **Natural Language Summaries** - Generate human-readable summaries

**Implementation:**

```typescript
class AiEnrichmentService {
  // 1. Classification
  async classify(alert: Alert): Promise<Classification> {
    // Use Gemini or GPT to classify
    const prompt = `
      Classify this fire incident:
      Type: ${alert.incidentType}
      Details: ${alert.incidentDetails}
      
      Categories: Residential, Commercial, Vehicle, Wildfire, Industrial
      Severity: 1-5
      Estimated Units Needed: 1-10
    `;
    
    const result = await this.geminiApi.generate(prompt);
    return JSON.parse(result);
  }
  
  // 2. Natural Language Summary
  async summarize(alert: EnrichedAlert): Promise<string> {
    return `
      ${alert.enriched.property.occupancy} structure fire at 
      ${alert.raw.address} (${alert.enriched.property.yearBuilt}, 
      ${alert.enriched.property.squareFeet} sq ft). 
      ${alert.enriched.fdCodes.length} units responding. 
      Property has ${alert.enriched.historicalContext.previousIncidents} 
      previous incidents.
    `;
  }
}
```

**ML Models (Edge & Cloud):**

1. **On-Device (Android):**
```kotlin
class EdgeClassifier {
    // TensorFlow Lite model (5MB)
    fun classifyPriority(parsedData: ParsedData): Priority {
        // Input: incidentType, keywords in details
        // Output: CRITICAL, HIGH, NORMAL, LOW
        // Runs in <50ms on device
    }
}
```

2. **Cloud (Cloud Function):**
```python
# Vertex AI model
class IncidentPredictor:
    def predict_escalation(self, alert: Alert) -> float:
        # Features: time of day, location, incident type, weather
        # Output: 0.0-1.0 probability of escalation
        # Training data: historical incidents with outcomes
```

---

### Phase 3: Advanced Features (Weeks 9-12)

#### 3.1 Real-Time Dashboard

**Tech Stack:**
- **Frontend:** Next.js (React)
- **Backend:** Firebase Cloud Functions
- **Database:** Firestore (real-time subscriptions)
- **Map:** Google Maps API
- **Charts:** Chart.js or D3.js

**Features:**
1. **Live Map** - Real-time incident markers
2. **Timeline** - Incident feed (Twitter-like)
3. **Analytics** - Response time, incident types, hot zones
4. **Unit Tracking** - Which FD units are where
5. **Historical Heatmap** - Incident density over time

**Sample Dashboard Component:**
```typescript
function IncidentDashboard() {
  const [incidents, setIncidents] = useState([]);
  
  useEffect(() => {
    // Real-time Firestore subscription
    const unsubscribe = firestore
      .collection('incidents')
      .where('timestamp', '>', Date.now() - 24 * 60 * 60 * 1000)
      .orderBy('timestamp', 'desc')
      .onSnapshot(snapshot => {
        const data = snapshot.docs.map(doc => doc.data());
        setIncidents(data);
      });
    
    return unsubscribe;
  }, []);
  
  return (
    <Dashboard>
      <LiveMap incidents={incidents} />
      <IncidentFeed incidents={incidents} />
      <Analytics incidents={incidents} />
    </Dashboard>
  );
}
```

---

#### 3.2 Multi-Channel Notifications

**Current:** Data flows one way (Device â†’ Sheet)

**Enterprise:** Bi-directional + multi-channel

**Notification Channels:**
1. **Mobile Push** (Firebase Cloud Messaging)
2. **Email** (SendGrid)
3. **SMS** (Twilio)
4. **Slack** (Webhook)
5. **PagerDuty** (API)
6. **Discord** (Webhook)
7. **Microsoft Teams** (Webhook)
8. **Voice Call** (Twilio)

**Routing Engine:**
```typescript
class NotificationRouter {
  async route(alert: EnrichedAlert) {
    const rules = await this.getRules(alert);
    
    for (const rule of rules) {
      if (rule.matches(alert)) {
        await this.sendVia(rule.channels, alert);
      }
    }
  }
}

// Example rules:
const rules = [
  {
    condition: alert => alert.raw.incidentType.includes('Fire'),
    channels: ['push', 'email', 'slack'],
    recipients: ['fire-dept-team']
  },
  {
    condition: alert => alert.enriched.severity >= 4,
    channels: ['push', 'sms', 'pagerduty', 'voice'],
    recipients: ['on-call-chief']
  }
];
```

---

#### 3.3 Advanced SMS Features

**Current SMS Limitations:**
- Only stores sender + message
- No threading/conversation tracking
- No two-way communication
- No auto-response
- No keyword-based routing

**Enterprise SMS:**

1. **Conversation Threading**
```typescript
interface SmsThread {
  threadId: string;
  participants: string[];
  messages: SmsMessage[];
  relatedIncident?: string; // Link to incident ID
}

class SmsThreadManager {
  async track(sms: SmsMessage): Promise<SmsThread> {
    // Group SMS by sender + time window
    const thread = await this.findOrCreateThread(sms.sender, '30m');
    thread.messages.push(sms);
    return thread;
  }
}
```

2. **Keyword-Based Auto-Response**
```typescript
class SmsAutoResponder {
  async respond(sms: SmsMessage): Promise<void> {
    const keywords = {
      'STATUS': () => this.getIncidentStatus(sms),
      'UNITS': () => this.getRespondingUnits(sms),
      'LOCATION': () => this.getIncidentLocation(sms),
      'HELP': () => this.showCommands()
    };
    
    const keyword = this.extractKeyword(sms.message);
    if (keyword in keywords) {
      const response = await keywords[keyword]();
      await this.twilioApi.send(sms.sender, response);
    }
  }
}

// Example:
// Incoming SMS: "STATUS #1845007"
// Auto-response: "Incident #1845007: Working Fire at 1107 Langford St. Units: E-691, L-233. Status: Under Control."
```

3. **Two-Way Command System**
```typescript
class SmsCommandHandler {
  commands = {
    'ACKNOWLEDGE': (incidentId) => this.markAcknowledged(incidentId),
    'ENROUTE': (incidentId) => this.markEnRoute(incidentId),
    'ONSCENE': (incidentId) => this.markOnScene(incidentId),
    'CLEAR': (incidentId) => this.markCleared(incidentId)
  };
  
  async execute(sms: SmsMessage) {
    // Parse: "ONSCENE #1845007"
    const [command, incidentId] = sms.message.split(' ');
    if (command in this.commands) {
      await this.commands[command](incidentId);
      // Update Firestore + Sheet + Notify stakeholders
    }
  }
}
```

4. **SMS Analytics**
```sql
-- BigQuery Analytics
SELECT 
  sender,
  COUNT(*) as message_count,
  AVG(response_time_seconds) as avg_response_time,
  SUM(CASE WHEN contains_keyword THEN 1 ELSE 0 END) as command_count
FROM sms_messages
WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)
GROUP BY sender
ORDER BY message_count DESC;
```

---

### Phase 4: Scalability & Reliability (Weeks 13-16)

#### 4.1 Microservices Architecture

**Current:** Monolithic Apps Script

**Enterprise:** Microservices on Cloud Run

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              API Gateway (Cloud Run)              â”‚
â”‚  - Rate limiting                                  â”‚
â”‚  - Authentication                                 â”‚
â”‚  - Request routing                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”œâ”€ Ingestion Service (Cloud Run)
        â”‚  - Receive alerts
        â”‚  - Validate & enqueue
        â”‚
        â”œâ”€ Processing Service (Cloud Run)
        â”‚  - Parse & transform
        â”‚  - Auto-scaling
        â”‚
        â”œâ”€ Enrichment Service (Cloud Run)
        â”‚  - Geocoding
        â”‚  - Property data
        â”‚  - ML inference
        â”‚
        â”œâ”€ Persistence Service (Cloud Run)
        â”‚  - Multi-database writes
        â”‚  - Transaction management
        â”‚
        â””â”€ Notification Service (Cloud Run)
           - Multi-channel dispatch
           - Retry logic
```

**Benefits:**
- **Independent scaling** - Scale enrichment without affecting ingestion
- **Fault isolation** - Geocoding failure doesn't break SMS
- **Technology flexibility** - Use Python for ML, Node for API
- **Team autonomy** - Different teams own different services

---

#### 4.2 Message Queue (Pub/Sub)

**Current:** Direct HTTP calls

**Enterprise:** Event-driven with Cloud Pub/Sub

```
Android App â†’ Pub/Sub Topic: "raw-alerts"
                    â†“
            Subscription: "parser"
                    â†“
            Cloud Function: parse()
                    â†“
            Pub/Sub Topic: "parsed-alerts"
                    â†“
            Subscription: "enrichment"
                    â†“
            Cloud Function: enrich()
                    â†“
            Pub/Sub Topic: "enriched-alerts"
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                      â”‚
    Subscription:          Subscription:
    "firestore-writer"     "notification-sender"
         â”‚                      â”‚
    Write to DB           Send notifications
```

**Benefits:**
- **Decoupling:** Services don't need to know about each other
- **Reliability:** Messages persisted, automatic retry
- **Scalability:** Auto-scales based on queue depth
- **Flexibility:** Add new consumers without changing producers

---

#### 4.3 High Availability

**Components:**

1. **Multi-Region Deployment**
```yaml
# Cloud Run service
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: ingestion-service
spec:
  template:
    spec:
      containers:
      - image: gcr.io/alerts-sheets/ingestion:v1
  traffic:
  - percent: 50
    latestRevision: false
    revisionName: ingestion-v1
    tag: us-east1
  - percent: 50
    latestRevision: false
    revisionName: ingestion-v2
    tag: us-west1
```

2. **Database Replication**
```
Firestore: Multi-region (automatic)
BigQuery: Cross-region dataset copies
Sheets: Google Drive (already replicated)
```

3. **Monitoring & Alerting**
```typescript
// Cloud Monitoring
const metrics = {
  'alerts_received': Counter,
  'parse_failures': Counter,
  'enrichment_latency': Histogram,
  'database_write_errors': Counter
};

// Alert policies
if (parse_failures > 10/min) {
  notify('on-call-engineer', 'HIGH', 'Parser failing');
}

if (enrichment_latency > 5s) {
  notify('ops-team', 'MEDIUM', 'Slow enrichment');
}
```

---

### Phase 5: Enterprise Features (Weeks 17-20)

#### 5.1 Multi-Tenancy

**Use Case:** Support multiple fire departments, each with isolated data

**Implementation:**
```typescript
interface Tenant {
  id: string;
  name: string;
  config: TenantConfig;
  users: User[];
  apiKey: string;
}

class TenantService {
  async isolate(request: Request): Promise<Tenant> {
    const apiKey = request.headers['X-API-Key'];
    const tenant = await this.lookup(apiKey);
    
    // All subsequent operations scoped to tenant
    return tenant;
  }
}

// Firestore structure:
/tenants/{tenantId}/incidents/{incidentId}
/tenants/{tenantId}/users/{userId}
/tenants/{tenantId}/config/settings
```

**Android App Updates:**
```kotlin
class TenantManager {
    private var currentTenant: String = ""
    
    fun setTenant(tenantId: String, apiKey: String) {
        PrefsManager.saveTenantId(context, tenantId)
        PrefsManager.saveApiKey(context, apiKey)
    }
    
    fun getHeaders(): Map<String, String> {
        return mapOf(
            "X-API-Key" to PrefsManager.getApiKey(context),
            "X-Tenant-ID" to PrefsManager.getTenantId(context)
        )
    }
}
```

---

#### 5.2 Role-Based Access Control (RBAC)

**Roles:**
```typescript
enum Role {
  ADMIN,          // Full access, manage users
  DISPATCHER,     // Create/update incidents
  RESPONDER,      // View + update status
  ANALYST,        // Read-only + analytics
  PUBLIC          // Public data only (redacted)
}

const permissions = {
  [Role.ADMIN]: ['*'],
  [Role.DISPATCHER]: ['incidents.create', 'incidents.update', 'units.dispatch'],
  [Role.RESPONDER]: ['incidents.view', 'incidents.updateStatus'],
  [Role.ANALYST]: ['incidents.view', 'analytics.query'],
  [Role.PUBLIC]: ['incidents.viewPublic']
};

class AuthService {
  async authorize(user: User, action: string): Promise<boolean> {
    const userPermissions = permissions[user.role];
    return userPermissions.includes('*') || userPermissions.includes(action);
  }
}
```

---

#### 5.3 Audit Logging

**Track all operations for compliance:**

```typescript
interface AuditLog {
  timestamp: Date;
  actor: User;
  action: string;
  resource: string;
  result: 'success' | 'failure';
  changes?: object;
  ipAddress: string;
  userAgent: string;
}

class AuditService {
  async log(entry: AuditLog) {
    // Write to immutable log (BigQuery)
    await this.bigquery.insert('audit_logs', entry);
    
    // Also write to Firestore for recent access
    await this.firestore.collection('audit').add(entry);
  }
}

// Usage:
await auditService.log({
  actor: currentUser,
  action: 'incident.update',
  resource: `incidents/${incidentId}`,
  result: 'success',
  changes: { status: 'closed' }
});
```

**Compliance Reports:**
```sql
-- Who accessed what incident?
SELECT 
  actor.email,
  action,
  resource,
  timestamp
FROM audit_logs
WHERE resource = 'incidents/1845007'
ORDER BY timestamp DESC;

-- Failed access attempts (security)
SELECT 
  actor.email,
  action,
  resource,
  COUNT(*) as attempts
FROM audit_logs
WHERE result = 'failure'
  AND timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)
GROUP BY actor.email, action, resource
HAVING attempts > 5;
```

---

### Phase 6: Advanced Analytics (Weeks 21-24)

#### 6.1 Predictive Analytics

**ML Models:**

1. **Response Time Prediction**
```python
# Train model on historical data
features = [
  'time_of_day',
  'day_of_week',
  'incident_type',
  'distance_from_station',
  'weather_conditions',
  'traffic_density'
]

target = 'response_time_minutes'

model = train_xgboost(features, target)

# Predict for new incident
predicted_time = model.predict(new_incident_features)
```

2. **Incident Escalation Prediction**
```python
# Binary classification: Will incident escalate?
features = [
  'initial_incident_type',
  'building_age',
  'building_construction',
  'time_to_first_unit',
  'weather',
  'historical_incidents_at_location'
]

target = 'did_escalate'  # 0 or 1

model = train_random_forest(features, target)

# Real-time prediction
if model.predict_proba(incident) > 0.7:
  notify_additional_units()
```

3. **Hotspot Detection**
```sql
-- Find areas with increasing incident frequency
WITH monthly_counts AS (
  SELECT 
    geohash,
    DATE_TRUNC(timestamp, MONTH) as month,
    COUNT(*) as incident_count
  FROM incidents
  WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 YEAR)
  GROUP BY geohash, month
)
SELECT 
  geohash,
  REGR_SLOPE(incident_count, UNIX_SECONDS(month)) as trend
FROM monthly_counts
GROUP BY geohash
HAVING trend > 0.1  -- Increasing trend
ORDER BY trend DESC;
```

---

#### 6.2 Business Intelligence Dashboard

**KPIs to Track:**

1. **Operational Metrics**
   - Average response time
   - Incidents per day/week/month
   - Most common incident types
   - Busiest times/days
   - Unit utilization rates

2. **Performance Metrics**
   - Data capture success rate (% of alerts captured)
   - Parse success rate (% of BNN successfully parsed)
   - Enrichment completion rate (% with property data)
   - Notification delivery rate (% successfully delivered)

3. **Cost Metrics**
   - API costs (geocoding, property data, ML)
   - Storage costs (Firestore, BigQuery, Sheets)
   - Compute costs (Cloud Functions, Cloud Run)
   - Cost per incident processed

**Dashboard Implementation:**
```typescript
// Looker Studio or custom dashboard
const dashboard = {
  widgets: [
    {
      type: 'metric',
      title: 'Incidents Today',
      query: 'SELECT COUNT(*) FROM incidents WHERE DATE(timestamp) = CURRENT_DATE()'
    },
    {
      type: 'chart',
      title: 'Incidents by Type (Last 30 Days)',
      query: `
        SELECT 
          incident_type,
          COUNT(*) as count
        FROM incidents
        WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)
        GROUP BY incident_type
        ORDER BY count DESC
      `
    },
    {
      type: 'map',
      title: 'Incident Heatmap',
      query: 'SELECT location, incident_type FROM incidents WHERE timestamp >= ...'
    }
  ]
};
```

---

## ğŸ“‹ Implementation Roadmap

### Summary Table

| Phase | Duration | Complexity | Priority | Dependencies |
|-------|----------|------------|----------|--------------|
| **Phase 1: Backend Modernization** | 4 weeks | High | P0 | None |
| **Phase 2: Enrichment Pipeline** | 4 weeks | Medium | P1 | Phase 1 |
| **Phase 3: Advanced Features** | 4 weeks | Medium | P1 | Phase 1 |
| **Phase 4: Scalability** | 4 weeks | High | P0 | Phase 1 |
| **Phase 5: Enterprise Features** | 4 weeks | Medium | P2 | Phase 1, 4 |
| **Phase 6: Advanced Analytics** | 4 weeks | High | P2 | Phase 1, 2 |

**Total Timeline:** 24 weeks (6 months)

---

### Detailed Sprint Plan

#### Sprint 1-4: Backend Modernization
**Week 1:**
- [ ] Design handler architecture
- [ ] Implement HandlerFactory
- [ ] Create BaseHandler abstract class
- [ ] Port BNN logic to BnnHandler

**Week 2:**
- [ ] Port SMS logic to SmsHandler
- [ ] Implement EmailHandler
- [ ] Implement WebhookHandler
- [ ] Write unit tests for all handlers

**Week 3:**
- [ ] Setup Firestore schema
- [ ] Setup BigQuery tables
- [ ] Implement DataStore interface
- [ ] Implement FirestoreStore

**Week 4:**
- [ ] Implement BigQueryStore
- [ ] Keep GoogleSheetsStore (backward compat)
- [ ] Deploy Cloud Functions
- [ ] Test end-to-end flow

#### Sprint 5-8: Enrichment Pipeline
**Week 5:**
- [ ] Setup Geocoding Service
- [ ] Integrate with existing Firestore geocode cache
- [ ] Implement fallback to Google Maps API
- [ ] Cache new results

**Week 6:**
- [ ] Setup Property Data Service
- [ ] Integrate Attom/Estated APIs
- [ ] Implement caching strategy
- [ ] Handle API rate limits

**Week 7:**
- [ ] Build FD Code Translation Service
- [ ] Populate Firestore fd_codes collection
- [ ] Implement lookup with caching
- [ ] Add coverage area polygons

**Week 8:**
- [ ] Integrate Gemini API for summaries
- [ ] Implement classification model
- [ ] Deploy enrichment pipeline
- [ ] Test with historical data

#### Sprint 9-12: Advanced Features
**Week 9:**
- [ ] Design dashboard UI (Next.js)
- [ ] Implement live map component
- [ ] Setup Firestore real-time subscriptions
- [ ] Deploy to Vercel/Firebase Hosting

**Week 10:**
- [ ] Implement timeline feed
- [ ] Build analytics charts
- [ ] Add filters and search
- [ ] Mobile-responsive design

**Week 11:**
- [ ] Setup notification router
- [ ] Integrate Firebase Cloud Messaging
- [ ] Integrate Twilio (SMS + Voice)
- [ ] Integrate SendGrid (Email)

**Week 12:**
- [ ] Integrate Slack webhooks
- [ ] Integrate PagerDuty API
- [ ] Implement routing rules engine
- [ ] Test multi-channel delivery

#### Sprint 13-16: Scalability
**Week 13:**
- [ ] Migrate to Cloud Run microservices
- [ ] Setup API Gateway
- [ ] Implement authentication
- [ ] Configure auto-scaling

**Week 14:**
- [ ] Setup Cloud Pub/Sub topics
- [ ] Migrate to event-driven architecture
- [ ] Implement dead-letter queues
- [ ] Configure retry policies

**Week 15:**
- [ ] Multi-region deployment
- [ ] Setup Cloud Load Balancing
- [ ] Configure Firestore replication
- [ ] Test failover scenarios

**Week 16:**
- [ ] Implement Cloud Monitoring
- [ ] Setup alert policies
- [ ] Create ops dashboards
- [ ] Document runbooks

#### Sprint 17-20: Enterprise Features
**Week 17:**
- [ ] Design multi-tenancy architecture
- [ ] Implement tenant isolation
- [ ] Update Android app for tenant support
- [ ] Migrate existing data to tenant structure

**Week 18:**
- [ ] Design RBAC system
- [ ] Implement role definitions
- [ ] Add permission checks to all endpoints
- [ ] Build user management UI

**Week 19:**
- [ ] Implement audit logging
- [ ] Setup BigQuery for logs
- [ ] Build audit trail viewer
- [ ] Create compliance reports

**Week 20:**
- [ ] Security audit
- [ ] Penetration testing
- [ ] Performance testing (load tests)
- [ ] Documentation update

#### Sprint 21-24: Advanced Analytics
**Week 21:**
- [ ] Collect historical data for ML
- [ ] Clean and prepare training data
- [ ] Train response time prediction model
- [ ] Validate model accuracy

**Week 22:**
- [ ] Train escalation prediction model
- [ ] Train hotspot detection model
- [ ] Deploy models to Vertex AI
- [ ] Integrate with enrichment pipeline

**Week 23:**
- [ ] Design BI dashboard (Looker Studio)
- [ ] Create operational reports
- [ ] Create financial reports
- [ ] Setup scheduled email reports

**Week 24:**
- [ ] Final testing and QA
- [ ] User acceptance testing
- [ ] Performance optimization
- [ ] Launch enterprise version

---

## ğŸ’° Cost Estimate (Monthly)

### Infrastructure Costs

| Service | Usage | Cost | Notes |
|---------|-------|------|-------|
| **Cloud Run** | 5 services, 1M requests | $25 | Within free tier initially |
| **Cloud Functions** | 10M invocations | $20 | Mostly free tier |
| **Firestore** | 50GB storage, 10M reads | $30 | Real-time database |
| **BigQuery** | 100GB storage, 1TB queries | $50 | Analytics warehouse |
| **Cloud Pub/Sub** | 100M messages | $40 | Message queue |
| **Cloud Storage** | 500GB | $10 | Backups, exports |
| **Google Maps API** | 10K geocodes | $50 | With caching optimization |
| **Attom/Estated API** | 5K lookups | $100 | Property data |
| **Gemini API** | 1M tokens | $10 | AI summaries (Flash) |
| **Twilio** | 1K SMS, 100 calls | $50 | Notifications |
| **SendGrid** | 10K emails | $15 | Email notifications |
| **Firebase Hosting** | 10GB bandwidth | $5 | Dashboard hosting |

**Total Monthly:** ~$405 initially, scales with usage

### Development Costs

| Phase | Estimated Hours | Rate | Total |
|-------|----------------|------|-------|
| Backend Modernization | 320 hours | $100/hr | $32,000 |
| Enrichment Pipeline | 320 hours | $100/hr | $32,000 |
| Advanced Features | 320 hours | $100/hr | $32,000 |
| Scalability | 320 hours | $100/hr | $32,000 |
| Enterprise Features | 320 hours | $100/hr | $32,000 |
| Advanced Analytics | 320 hours | $100/hr | $32,000 |

**Total Development:** $192,000 (6 months, 1 developer @ $100/hr)

**Alternative:** Phased approach, start with Phase 1-2 ($64,000)

---

## ğŸ¯ Success Metrics

### Technical Metrics
- [ ] 99.9% uptime
- [ ] <500ms p99 latency for ingestion
- [ ] 100% data capture rate (no lost alerts)
- [ ] 95% parse success rate
- [ ] 90% enrichment completion rate
- [ ] Auto-scaling to 10K incidents/hour

### Business Metrics
- [ ] Support 10+ fire departments (multi-tenant)
- [ ] 100+ active users
- [ ] 1M+ incidents processed
- [ ] <$0.50 cost per incident processed
- [ ] 50% reduction in manual data entry
- [ ] 30% faster incident response time

---

## ğŸ“š Documentation Requirements

### Technical Documentation
1. **Architecture Diagrams** - System design, data flow
2. **API Documentation** - OpenAPI/Swagger specs
3. **Database Schema** - Firestore, BigQuery, Sheets
4. **Deployment Guide** - CI/CD, infrastructure as code
5. **Monitoring Guide** - Metrics, alerts, troubleshooting

### User Documentation
1. **Admin Guide** - Tenant management, user roles
2. **Dispatcher Guide** - Creating/updating incidents
3. **Responder Guide** - Mobile app usage
4. **Analyst Guide** - Running reports, dashboards
5. **API Guide** - Integration for third parties

### Operations Documentation
1. **Runbooks** - Common operational tasks
2. **Incident Response** - Handling outages
3. **Scaling Guide** - When/how to scale
4. **Backup/Recovery** - Disaster recovery procedures
5. **Security Guide** - Security best practices

---

## âœ… Next Steps

### Immediate (This Week)
1. **Deploy SMS Fix** - Complete current branch (sms-configure)
2. **Verify BNN Still Works** - Regression test
3. **Document Current State** - Baseline for future improvements

### Short Term (Next Month)
1. **Evaluate Cloud Migration** - Cost-benefit analysis
2. **Pilot Firestore** - Small-scale test with dual-write
3. **Geocoding PoC** - Test reusing existing cache
4. **Setup Development Environment** - Cloud project, staging

### Medium Term (3-6 Months)
1. **Phase 1 Implementation** - Backend modernization
2. **Phase 2 Implementation** - Enrichment pipeline
3. **User Testing** - Alpha test with friendly fire dept
4. **Iterative Improvements** - Based on feedback

### Long Term (6-12 Months)
1. **Full Enterprise Rollout** - All phases complete
2. **Multi-Tenant Launch** - Onboard multiple departments
3. **Advanced Analytics** - ML models in production
4. **Platform Maturity** - Monitoring, optimization, cost reduction

---

**This upgrade path transforms alerts-sheets from a working prototype into an enterprise-grade platform capable of handling millions of incidents across multiple organizations with advanced AI/ML capabilities, real-time analytics, and multi-channel notifications.**

---

## ğŸ”— Appendix

### A. Technology Stack Comparison

| Layer | Current | Enterprise |
|-------|---------|------------|
| **Mobile** | Android (Kotlin) | Android + iOS (Flutter/React Native) |
| **Backend** | Google Apps Script | Cloud Functions + Cloud Run |
| **Database** | Google Sheets | Firestore + BigQuery + Sheets |
| **Queue** | SQLite (local) | Cloud Pub/Sub |
| **APIs** | None | Maps, Attom, Gemini, Twilio |
| **Monitoring** | adb logcat | Cloud Monitoring + Logging |
| **Frontend** | Android app only | Web dashboard + Mobile apps |

### B. Migration Strategy

**Zero-Downtime Migration:**
1. Deploy new services alongside existing Apps Script
2. Dual-write to both systems (Sheets + Firestore)
3. Verify data consistency for 1 week
4. Switch primary to Firestore
5. Keep Sheets as read-only view
6. Decommission Apps Script after 1 month

### C. Team Structure

**Recommended Team (Full Enterprise Build):**
- 1x Tech Lead / Architect
- 2x Backend Engineers (Cloud Functions, APIs)
- 1x Frontend Engineer (Dashboard, mobile improvements)
- 1x ML Engineer (Enrichment, analytics)
- 1x DevOps Engineer (Infrastructure, monitoring)
- 1x QA Engineer (Testing, validation)

**Minimum Viable Team:**
- 1x Full-stack Engineer (can handle Phases 1-3)
- 1x DevOps/Backend Engineer (scalability)

---

**Enterprise Upgrade Path Complete!** ğŸš€

